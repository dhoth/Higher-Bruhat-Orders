{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as iter\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#B_3 Example with numbering changes:\n",
    "long_words = {'usutsutst': np.array([[-3,-2],[-3,-1],[-2,-1],[-3,3],[-3,2],[-3,1],[-2,2],[-2,1],[-1,1]]),\n",
    "              'ustusutst': np.array([[-3,-2],[-3,-1],[-2,-1],[-3,3],[-3,2],[-2,2],[-3,1],[-2,1],[-1,1]]),\n",
    "              'usutstust': np.array([[-3,-2],[-3,-1],[-3,3],[-2,-1],[-3,2],[-3,1],[-2,2],[-2,1],[-1,1]]),\n",
    "              'usutsusts': np.array([[-2,-1],[-3,-1],[-3,-2],[-3,3],[-3,2],[-3,1],[-2,2],[-2,1],[-1,1]]),\n",
    "              'ustustust': np.array([[-3,-2],[-3,-1],[-3,3],[-2,-1],[-3,2],[-2,2],[-3,1],[-2,1],[-1,1]]),\n",
    "              'ustususts': np.array([[-2,-1],[-3,-1],[-3,-2],[-3,3],[-3,2],[-2,2],[-3,1],[-2,1],[-1,1]]),\n",
    "              'usustsust': np.array([[-3,-2],[-3,-1],[-3,3],[-3,1],[-3,2],[-2,-1],[-2,2],[-2,1],[-1,1]]),\n",
    "              'ustsusuts': np.array([[-2,-1],[-3,-1],[-2,2],[-3,2],[-3,3],[-3,-2],[-3,1],[-2,1],[-1,1]]),\n",
    "              'susutsust': np.array([[-3,-2],[-3,-1],[-3,3],[-3,1],[-3,2],[-1,1],[-2,1],[-2,2],[-2,-1]]),\n",
    "              'ustsustus': np.array([[-2,-1],[-2,2],[-3,-1],[-3,2],[-3,3],[-3,-2],[-3,1],[-2,1],[-1,1]]),\n",
    "              'utstusuts': np.array([[-2,-1],[-3,-1],[-2,2],[-3,2],[-3,3],[-2,1],[-3,1],[-3,-2],[-1,1]]),\n",
    "              'sustusust': np.array([[-3,-2],[-3,-1],[-3,3],[-3,1],[-1,1],[-3,2],[-2,1],[-2,2],[-2,-1]]),\n",
    "              'utstustus': np.array([[-2,-1],[-2,2],[-3,-1],[-3,2],[-3,3],[-2,1],[-3,1],[-3,-2],[-1,1]]),\n",
    "              'tustusuts': np.array([[-2,-1],[-3,-1],[-2,2],[-3,2],[-3,3],[-2,1],[-3,1],[-1,1],[-3,-2]]),\n",
    "              'utsutsuts': np.array([[-2,-1],[-3,-1],[-2,2],[-3,2],[-2,1],[-3,3],[-3,1],[-3,-2],[-1,1]]),\n",
    "              'sustsusut': np.array([[-3,-2],[-1,1],[-3,1],[-3,3],[-3,-1],[-3,2],[-2,1],[-2,2],[-2,-1]]),\n",
    "              'tustustus': np.array([[-2,-1],[-2,2],[-3,-1],[-3,2],[-3,3],[-2,1],[-3,1],[-1,1],[-3,-2]]),\n",
    "              'utsutstus': np.array([[-2,-1],[-2,2],[-3,-1],[-3,2],[-2,1],[-3,3],[-3,1],[-3,-2],[-1,1]]),\n",
    "              'tusutsuts': np.array([[-2,-1],[-3,-1],[-2,2],[-3,2],[-2,1],[-3,3],[-3,1],[-1,1],[-3,-2]]),         \n",
    "              'sustsustu': np.array([[-1,1],[-3,-2],[-3,1],[-3,3],[-3,-1],[-3,2],[-2,1],[-2,2],[-2,-1]]),\n",
    "              'sutstusut': np.array([[-3,-2],[-1,1],[-3,1],[-3,3],[-2,1],[-3,2],[-3,-1],[-2,2],[-2,-1]]),\n",
    "              'tusutstus': np.array([[-2,-1],[-2,2],[-3,-1],[-3,2],[-2,1],[-3,3],[-3,1],[-1,1],[-3,-2]]),\n",
    "              'utsustsus': np.array([[-2,-1],[-2,2],[-2,1],[-3,2],[-3,-1],[-3,3],[-3,1],[-3,-2],[-1,1]]),\n",
    "              'sutstustu': np.array([[-1,1],[-3,-2],[-3,1],[-3,3],[-2,1],[-3,2],[-3,-1],[-2,2],[-2,-1]]),\n",
    "              'stustusut': np.array([[-3,-2],[-1,1],[-3,1],[-3,3],[-2,1],[-3,2],[-2,2],[-3,-1],[-2,-1]]),\n",
    "              'sutsutsut': np.array([[-3,-2],[-1,1],[-3,1],[-2,1],[-3,3],[-3,2],[-3,-1],[-2,2],[-2,-1]]),\n",
    "              'tusustsus': np.array([[-2,-1],[-2,2],[-2,1],[-3,2],[-3,-1],[-3,3],[-3,1],[-1,1],[-3,-2]]),\n",
    "              'stustustu': np.array([[-1,1],[-3,-2],[-3,1],[-3,3],[-2,1],[-3,2],[-2,2],[-3,-1],[-2,-1]]),\n",
    "              'sutsutstu': np.array([[-1,1],[-3,-2],[-3,1],[-2,1],[-3,3],[-3,2],[-3,-1],[-2,2],[-2,-1]]),\n",
    "              'stusutsut': np.array([[-3,-2],[-1,1],[-3,1],[-2,1],[-3,3],[-3,2],[-2,2],[-3,-1],[-2,-1]]),\n",
    "              'tsusutsus': np.array([[-2,-1],[-2,2],[-2,1],[-3,2],[-1,1],[-3,1],[-3,3],[-3,-1],[-3,-2]]),\n",
    "              'stusutstu': np.array([[-1,1],[-3,-2],[-3,1],[-2,1],[-3,3],[-3,2],[-2,2],[-3,-1],[-2,-1]]),\n",
    "              'sutsustsu': np.array([[-1,1],[-2,1],[-3,1],[-3,-2],[-3,3],[-3,2],[-3,-1],[-2,2],[-2,-1]]),\n",
    "              'tsustusus': np.array([[-2,-1],[-2,2],[-2,1],[-1,1],[-3,2],[-3,1],[-3,3],[-3,-1],[-3,-2]]),\n",
    "              'stusustsu': np.array([[-1,1],[-2,1],[-3,1],[-3,-2],[-3,3],[-3,2],[-2,2],[-3,-1],[-2,-1]]),\n",
    "              'tsustsusu': np.array([[-1,1],[-2,1],[-2,2],[-2,-1],[-3,2],[-3,1],[-3,3],[-3,-1],[-3,-2]]),\n",
    "              'stsusutsu': np.array([[-1,1],[-2,1],[-3,1],[-2,2],[-3,2],[-3,3],[-3,-2],[-3,-1],[-2,-1]]),\n",
    "              'tsutstusu': np.array([[-1,1],[-2,1],[-2,2],[-3,1],[-3,2],[-2,-1],[-3,3],[-3,-1],[-3,-2]]),\n",
    "              'stsustusu': np.array([[-1,1],[-2,1],[-2,2],[-3,1],[-3,2],[-3,3],[-3,-2],[-3,-1],[-2,-1]]),\n",
    "              'tstusutsu': np.array([[-1,1],[-2,1],[-3,1],[-2,2],[-3,2],[-3,3],[-2,-1],[-3,-1],[-3,-2]]),\n",
    "              'tstustusu': np.array([[-1,1],[-2,1],[-2,2],[-3,1],[-3,2],[-3,3],[-2,-1],[-3,-1],[-3,-2]]),\n",
    "              'tsutsutsu': np.array([[-1,1],[-2,1],[-3,1],[-2,2],[-3,2],[-2,-1],[-3,3],[-3,-1],[-3,-2]])\n",
    "             }\n",
    "\n",
    "place = [-2,-1],[-3,2],[-3,1]\n",
    "r_place = [-3,1],[-3,2],[-2,-1]\n",
    "w = 'usutsutst'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns if a rep is a type two set.\n",
    "def is_type_one(rep):\n",
    "    rep = np.array(rep)\n",
    "    return len(rep) == len(set(abs(rep)))\n",
    "#FINISH\n",
    "def is_type_two(rep):\n",
    "    rep = preferred_rep(rep)\n",
    "    return (len(np.intersect1d(rep,abs(rep))) == 1) and (-rep[-2] == rep[-1])\n",
    "#Returns the preferred representative of the input\n",
    "def preferred_rep(rep):\n",
    "    rep = np.array(rep)\n",
    "    big = int(np.where(abs(rep.max()) >= abs(rep.min()), rep.max(), rep.min()))\n",
    "    pref_rep = np.sort(np.where(big < 0, rep, -rep))\n",
    "    first_pos = next((x[0] for x in enumerate(pref_rep) if x[1] > 0),-1)\n",
    "    if first_pos != -1:\n",
    "        pref_rep[first_pos:] = list(reversed(pref_rep[first_pos:]))\n",
    "    return np.array(pref_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_cases = np.array([[-3,-2,-1],[-3,-2,1],[-1,3,2],[-1,1,2],[-1,-2,1],[-1,-2,3]])\n",
    "# for x in test_cases:\n",
    "#     pref_x = preferred_rep(x)\n",
    "#     print(\"{} is type one: {}\\n {} is its preferred rep \\n Its preferred rep is type one: {}\".format(\n",
    "#         x, is_type_one(x), pref_x, is_type_one(pref_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_order(rep1, rep2):\n",
    "    rep1, rep2 = preferred_rep(rep1), preferred_rep(rep2)\n",
    "    one_pos = len(np.intersect1d(rep1,abs(rep1)))\n",
    "    two_pos = len(np.intersect1d(rep2,abs(rep2)))\n",
    "    if one_pos < two_pos: #Does rep1 have fewer positive numbers than rep2\n",
    "        return True\n",
    "    elif one_pos > two_pos:\n",
    "        return False\n",
    "    else:\n",
    "        if one_pos == 0: #This means that both rep1 and rep2 look like [-x,-y]\n",
    "            if rep1[0] < rep2[0]:\n",
    "                return True\n",
    "            elif rep1[0] > rep2[0]:\n",
    "                return False\n",
    "            else:\n",
    "                return rep1[1] < rep2[1]\n",
    "        else:\n",
    "            if rep1[0] < rep2[0]:\n",
    "                return True\n",
    "            elif rep1[0] == rep2[0]:\n",
    "                return rep1[1] > rep2[1]\n",
    "    return False\n",
    "\n",
    "def three_order(rep1, rep2):\n",
    "    rep1,rep2 = preferred_rep(rep1), preferred_rep(rep2)\n",
    "    one_pos = len(np.intersect1d(rep1,abs(rep1))) #Finds the number of positive elements in rep1\n",
    "    two_pos = len(np.intersect1d(rep2,abs(rep2))) #Finds the number of positive elements in rep2\n",
    "    if one_pos < two_pos: \n",
    "        return True\n",
    "    elif two_pos < one_pos:\n",
    "        return False\n",
    "    else:\n",
    "        if one_pos == 0:\n",
    "            if rep1[0] < rep2[0]:\n",
    "                return True\n",
    "            elif rep1[0] > rep2[0]:\n",
    "                return False\n",
    "            else:\n",
    "                if rep1[1] < rep2[1]:\n",
    "                    return True\n",
    "                elif rep1[1] > rep2[1]:\n",
    "                    return False\n",
    "                else:\n",
    "                    return rep1[2] < rep2[2]\n",
    "        elif one_pos == 1:\n",
    "            if two_order(rep1[0:2], rep2[0:2]):\n",
    "                return True\n",
    "            elif (rep1[0] == rep2[0]) and (rep1[1] == rep2[1]):\n",
    "                return rep1[-1] > rep2[-1]\n",
    "            else:\n",
    "                return False\n",
    "        else: #Both elements have two positive entries #Try toggling this (actual is rep1[0] >). Try rep1[0]<\n",
    "            if rep1[0] > rep2[0]: #actual\n",
    "            #if rep1[0] < rep2[0]:\n",
    "                return True\n",
    "            elif rep1[0] == rep2[0]:\n",
    "                return two_order(-rep1[1:3], -rep2[1:3]) #actual\n",
    "                #return two_order(-rep2[1:3],-rep1[1:3])\n",
    "            else:\n",
    "                return False\n",
    "    return \"Ya Done Messed Up\"\n",
    "def four_order(rep1,rep2, hard_order):\n",
    "    if hard_order == None:\n",
    "        raise ValueError('You have not given me a hard order')\n",
    "    else:\n",
    "        return hard_order.index(rep1) < hard_order.index(rep2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mergesort on lists\n",
    "def merge_sort(lists, hard_order = None):\n",
    "    if len(lists) <= 1:\n",
    "        return lists\n",
    "    m = int(len(lists) / 2)\n",
    "    left_lists = lists[:m]\n",
    "    right_lists = lists[m:]\n",
    "    left_lists = merge_sort(left_lists, hard_order)\n",
    "    right_lists = merge_sort(right_lists, hard_order)\n",
    "    return merge(left_lists, right_lists,hard_order)\n",
    "def merge(l_list, r_list, hard_order):\n",
    "    merged = []\n",
    "    l, r = 0,0\n",
    "    order = len(l_list[0])\n",
    "    while (l < len(l_list)) and (r < len(r_list)):\n",
    "        if order == 2:\n",
    "            if two_order(l_list[l], r_list[r]):\n",
    "                merged.append(l_list[l])\n",
    "                l+=1\n",
    "            else:\n",
    "                merged.append(r_list[r])\n",
    "                r+=1\n",
    "        elif order == 3:\n",
    "            if three_order(l_list[l], r_list[r]):\n",
    "                merged.append(l_list[l])\n",
    "                #print(\"{} is less than {}\".format(l_list[l],r_list[r]))\n",
    "                l+=1\n",
    "            else:\n",
    "                merged.append(r_list[r])\n",
    "                #print(\"{} is less than {}\".format(r_list[r],l_list[l]))\n",
    "                r+=1\n",
    "        elif order == 4: #Use the hard order\n",
    "            if four_order(l_list[l],r_list[r],hard_order):\n",
    "                merged.append(l_list[l])\n",
    "                l+=1\n",
    "            else:\n",
    "                merged.append(r_list[r])\n",
    "                r+=1\n",
    "        else:\n",
    "            raise ValueError('You are not in the k = 2, k = 3, or k = 4 case')\n",
    "    if l < len(l_list):\n",
    "        while l < len(l_list):\n",
    "            merged.append(l_list[l])\n",
    "            l+=1\n",
    "    else:\n",
    "        while r < len(r_list):\n",
    "            merged.append(r_list[r])\n",
    "            r+=1\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Order Test Cases\n",
    "# two_tests = np.array([np.array([-4,-3]), np.array([-4,-2]), np.array([-3,-1]), np.array([-1,1]), np.array([-3,3])])\n",
    "# for i in iter.combinations(two_tests, 2):\n",
    "#     s = \"{} is smaller than {}: {}\".format(i[0],i[1],two_order(i[0],i[1]))\n",
    "#     print(s)\n",
    "# #three_order(np.array([-3,2,1]),np.array([-3,-1,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate all the type one and type two sets by returning their preferred representatives\n",
    "def type_one_sets(J, k, sort = False):\n",
    "    if len(J) < k:\n",
    "        return \"Ya Done Goofed\"\n",
    "    candidates = iter.combinations(J, k)\n",
    "    one_sets = filter(is_type_one,candidates)\n",
    "    one_sets = [preferred_rep(x) for x in one_sets]\n",
    "    one_sets = np.unique(one_sets,axis = 0)\n",
    "    if k <= 3:\n",
    "        return merge_sort(one_sets)\n",
    "    else:\n",
    "        return one_sets\n",
    "def type_two_sets(J,k,sort = False):\n",
    "    if len(J) < k:\n",
    "        return 'Ya Done Goofed'\n",
    "    candidates = iter.combinations(J,k)\n",
    "    two_sets = filter(is_type_two, candidates)\n",
    "    two_sets = [preferred_rep(x) for x in two_sets]\n",
    "    two_sets = np.unique(two_sets, axis = 0)\n",
    "    if k <= 3:\n",
    "        return merge_sort(two_sets)\n",
    "    else:\n",
    "        return two_sets\n",
    "def all_sets(J, k, sort = False): \n",
    "    if k <= 3:\n",
    "        return merge_sort(list(type_one_sets(J,k, sort = True))+list(type_two_sets(J,k,sort = True)))\n",
    "    else:\n",
    "        return list(type_one_sets(J,k))+list(type_two_sets(J,k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_packet(x,y):\n",
    "    packet = []\n",
    "    x = preferred_rep(x)\n",
    "    y = preferred_rep(y)\n",
    "    if np.all(x == y):\n",
    "        raise ValueError('Inputs are the same')\n",
    "    k = len(x)\n",
    "    is_x_one = is_type_one(x)\n",
    "    is_y_one = is_type_one(y)\n",
    "    if x[0] > y[0]: #make sure x_min <= y_min\n",
    "        hold = x.copy()\n",
    "        x = y.copy()\n",
    "        y = hold\n",
    "    if (is_x_one == False) and (is_y_one == False):\n",
    "        x_neg, y_neg = x[:-1],y[:-1]\n",
    "        intersection = np.intersect1d(x_neg,y_neg)\n",
    "        diff = np.setdiff1d(x_neg,y_neg, assume_unique = True)\n",
    "        if len(diff) == 1:\n",
    "            packet = list(y_neg.copy())\n",
    "            packet.append(diff[0])\n",
    "            packet.sort()\n",
    "            packet.append(-packet[-1])\n",
    "    elif (is_x_one == True) and (is_y_one == True):\n",
    "        x_min, y_min = x[0],y[0]\n",
    "        if x_min == y_min:\n",
    "            abs_x_right, abs_y_right = abs(x[1:]),abs(y[1:])\n",
    "            if len(np.intersect1d(abs_x_right,abs_y_right)) == len(abs_x_right): #This means that adding a star works\n",
    "                packet = x.copy()\n",
    "                packet = list(-abs(packet))\n",
    "                packet.sort()\n",
    "                packet.append(-packet[-1])\n",
    "            else: #Still need to check if x and y just differ by one element\n",
    "                diff = np.setdiff1d(y[1:],x[1:])\n",
    "                if len(diff) == 1:\n",
    "                    packet = list(x.copy())\n",
    "                    packet.append(diff[0])\n",
    "                    packet.sort()\n",
    "                else:\n",
    "                    next\n",
    "        else: #This is when x_min < y_min. You must rely on a flip here...nah fam you could just have to add a single guy!\n",
    "            x_max_pos = np.max(x)\n",
    "            if -x_max_pos == y_min: #This means that a packet flip is available.\n",
    "                x_right_toss = np.setdiff1d(x[1:],x_max_pos)\n",
    "                y_right = y[1:]\n",
    "                diff = np.setdiff1d(y_right, -x_right_toss)\n",
    "                if len(diff) == 1:\n",
    "                    packet = list(x.copy())\n",
    "                    packet.append(-diff[0])\n",
    "            else:\n",
    "                x_diff = np.setdiff1d(x,y)\n",
    "                y_diff = np.setdiff1d(y,x)\n",
    "                if len(x_diff) == 1 and len(y_diff) == 1: #so x intersect y has size k - 2\n",
    "                    if x_diff[0] == -y_diff[0]:#Probably can't happen?\n",
    "                        packet = list(x.copy())\n",
    "                        packet.append(-packet[-1])\n",
    "                        packet.sort()\n",
    "                    else:\n",
    "                        packet = list(x.copy())\n",
    "                        packet.append(y_diff[0])\n",
    "                        packet.sort()\n",
    "    else:\n",
    "        if is_y_one == True: #make it so that x is always type one\n",
    "            hold = x.copy()\n",
    "            x = y.copy()\n",
    "            y = hold\n",
    "        abs_x,abs_y = abs(x),abs(y)\n",
    "        if len(np.intersect1d(abs_x,abs_y)) == k - 1:\n",
    "            packet = list(-abs(x))\n",
    "            packet.sort()\n",
    "            packet.append(-packet[-1])\n",
    "        else:\n",
    "            next\n",
    "    if len(packet) > 0:\n",
    "        return preferred_rep(packet)\n",
    "    return []\n",
    "\n",
    "def good_in_packet(x,y,one_packets, two_packets):\n",
    "    packet = []\n",
    "    x = list(preferred_rep(x))\n",
    "    y = list(preferred_rep(y))\n",
    "    if np.all(x == y):\n",
    "        raise ValueError('Inputs are the same')\n",
    "    for a in one_packets:\n",
    "        if x in one_packets[a] and y in one_packets[a]:\n",
    "            packet = a\n",
    "    for a in two_packets:\n",
    "        if x in two_packets[a] and y in two_packets[a]:\n",
    "            packet = a\n",
    "        if len(packet) > 0:\n",
    "            return preferred_rep(packet)\n",
    "    return packet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is working\n",
    "# x = [-3,1]\n",
    "# y = [-2,1]\n",
    "# in_packet(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finds commuting elements in an expression\n",
    "#Takes in a list of elements all in their preferred representation\n",
    "#Only works for k > 1\n",
    "def find_equiv(expression):\n",
    "    equivalences = []\n",
    "    i = 0\n",
    "    for x,y in zip(expression[0:-1],expression[1:]):\n",
    "        if in_packet(x,y) == []:\n",
    "            equivalences.append(np.array([i,i+1,x,y]))\n",
    "        i+=1    \n",
    "    return equivalences\n",
    "#Checks if a subexpression is actually a packet in lex order\n",
    "def pack_in_order(packet,subexp):\n",
    "    if len(packet) != len(subexp):\n",
    "        return False\n",
    "    for x,y in zip(packet, subexp):\n",
    "        if np.all(x == y) == False:\n",
    "            return False\n",
    "    return True\n",
    "#Takes in a set and returns its k-packets\n",
    "def get_packet(J,k):\n",
    "    if is_type_one(J):\n",
    "        return type_one_sets(J,k)\n",
    "    else:\n",
    "        J = np.union1d(J, -J)\n",
    "        return all_sets(J,k)\n",
    "    \n",
    "#Takes in a word of length k as well as a collection of sets of length n\n",
    "#Returns all the length n words whose k-packets contain the word\n",
    "#The n_sets should all be sets, while word should be a numpy array\n",
    "def packets_containing(type_one_n_sets, type_two_n_sets, word):\n",
    "    packets = []\n",
    "    if type(word) == list:\n",
    "        word = np.array(word)\n",
    "    word_set = set(word)\n",
    "    if is_type_one(word):\n",
    "        neg_word_set = set(-word)\n",
    "        for s in type_one_n_sets:\n",
    "            if (word_set.issubset(s)) or (neg_word_set.issubset(s)):\n",
    "                packets.append(preferred_rep(list(s)))\n",
    "        for s in type_two_n_sets:\n",
    "            s_array = preferred_rep(np.array(list(s)))[:-1]\n",
    "            big_s = set(np.union1d(s_array,-s_array))\n",
    "            if word_set.issubset(big_s):\n",
    "                packets.append(preferred_rep(list(s)))\n",
    "            \n",
    "    else: #So word is a type two word. It can only be found in type two packets\n",
    "        concat_word = set(word[:-1])\n",
    "        for s in type_two_n_sets:\n",
    "            if concat_word.issubset(s):\n",
    "                packets.append(preferred_rep(list(s)))   \n",
    "    return packets\n",
    "#Takes in an expression and finds all of the packets that can be flipped <-- Seems to work?\n",
    "def find_packets(type_one_n_sets, type_two_n_sets, expression):\n",
    "    k = len(expression[0])\n",
    "    in_order_packets = {}\n",
    "    in_order_indices = {}\n",
    "    packet = []\n",
    "    for i in range(0,len(expression)-1):\n",
    "        #print('The characters are {} and {}'.format(expression[i],expression[i+1]))\n",
    "        poss_packs_1 = set([tuple(x) for x in packets_containing(type_one_n_sets, type_two_n_sets, expression[i])])\n",
    "        #Check if next word is in poss_packs packets\n",
    "        poss_packs_2 = set([tuple(x) for x in packets_containing(type_one_n_sets, type_two_n_sets, expression[i+1])])\n",
    "        poss_packs = [np.array(x) for x in poss_packs_1 & poss_packs_2]\n",
    "        if len(poss_packs) == 0:\n",
    "            next\n",
    "            #print(\"{} and {} are not in a packet together\".format(expression[i],expression[i+1]))\n",
    "        #else:\n",
    "            #print('{} and {} are in a packet together: {}'.format(expression[i],expression[i+1],poss_packs))\n",
    "        for p in poss_packs:\n",
    "            if is_type_one(p):\n",
    "                #print('{} and {} are in a type one packet together. \\n That packet is {}'.format(expression[i],expression[i+1],p))\n",
    "                packet = type_one_sets(p,k)\n",
    "            else:\n",
    "                #print('{} and {} are in a type two packet together. \\n That packet is {}'.format(expression[i],expression[i+1],p))\n",
    "                J = np.union1d(p,-p)\n",
    "                packet = all_sets(J,k)\n",
    "            if (i + len(packet)) <= len(expression):\n",
    "                subexp = expression[i:i+len(packet)] \n",
    "               # print('You are checking the packet {} in the subexpression {}'.format(poss_pack,subexp))\n",
    "                if pack_in_order(packet,subexp):\n",
    "                    in_order_packets[tuple(p)] = packet\n",
    "                    in_order_indices[tuple(p)] = [i, i+len(packet)-1]\n",
    "    return in_order_packets,in_order_indices\n",
    "\n",
    "def flip(exp, indices):\n",
    "    copy = [k for k in exp]\n",
    "    start = indices[0]\n",
    "    end = indices[1]\n",
    "    for i in range(0,end-start+1):\n",
    "        copy[start+i] = exp[end-i]\n",
    "    return copy\n",
    "\n",
    "def adj_words(type_one_n_sets, type_two_n_sets, word,flips = True):\n",
    "    e_m = []\n",
    "    f_m = []\n",
    "    p_m = []\n",
    "    for e in find_equiv(word):\n",
    "        e_m.append(flip(word,[e[0],e[1]]))\n",
    "    if flips == True:\n",
    "        f1,f2 = find_packets(type_one_n_sets, type_two_n_sets, word)\n",
    "        for f in f2:\n",
    "            f_m.append(flip(word,f2[f]))\n",
    "            p_m.append(f)\n",
    "    e_m.reverse()\n",
    "    f_m.reverse()\n",
    "    p_m.reverse()\n",
    "    return e_m,f_m,p_m\n",
    "\n",
    "def build_graph(type_one_n_sets, type_two_n_sets,start_word, add_flips = True):\n",
    "    checked_words = [start_word]\n",
    "    unchecked_words = []\n",
    "    e_connections = {0: []}\n",
    "    f_connections = {0: []}\n",
    "    p_connections = {0: []}\n",
    "    \n",
    "    e_moves,f_moves,p_moves = adj_words(type_one_n_sets, type_two_n_sets, start_word, flips = True)\n",
    "    for e in e_moves:\n",
    "        #if np.any([np.all(np.array(e) == x) for x in unchecked_words]) == False:\n",
    "        if e not in unchecked_words:\n",
    "            unchecked_words.append(e)\n",
    "            i = len(checked_words) + len(unchecked_words) - 1\n",
    "            e_connections[i] = []\n",
    "            f_connections[i] = []\n",
    "            p_connections[i] = []\n",
    "        i = checked_words.index(start_word)\n",
    "        e_connections[i].append(e)\n",
    "    for f in range(0,len(f_moves)):\n",
    "        if (f_moves[f] not in unchecked_words) and (add_flips == True):\n",
    "            unchecked_words.append(f_moves[f])\n",
    "            i = len(checked_words) + len(unchecked_words) - 1\n",
    "            e_connections[i] = []\n",
    "            f_connections[i] = []\n",
    "            p_connections[i] = []\n",
    "        i = checked_words.index(start_word)\n",
    "        f_connections[i].append(f_moves[f])\n",
    "        p_connections[i].append(p_moves[f])\n",
    "   # print(len(checked_words),len(unchecked_words))\n",
    "    while len(unchecked_words) != 0:\n",
    "        cur_word = unchecked_words.pop(0)\n",
    "        checked_words.append(cur_word)\n",
    "        e_moves,f_moves,p_moves = adj_words(type_one_n_sets, type_two_n_sets,cur_word,flips = True)\n",
    "        for e in e_moves:\n",
    "            if (e not in unchecked_words) and (e not in checked_words):\n",
    "                unchecked_words.append(e)\n",
    "                i = len(checked_words) + len(unchecked_words) - 1\n",
    "                e_connections[i] = []\n",
    "                f_connections[i] = []\n",
    "                p_connections[i] = []\n",
    "            i = checked_words.index(cur_word)\n",
    "            e_connections[i].append(e)\n",
    "        for f in range(0,len(f_moves)):\n",
    "            if (f_moves[f] not in unchecked_words) and (f_moves[f] not in checked_words) and (add_flips == True):\n",
    "                unchecked_words.append(f_moves[f])\n",
    "                i = len(checked_words) + len(unchecked_words) - 1\n",
    "                e_connections[i] = []\n",
    "                f_connections[i] = []\n",
    "                p_connections[i] = []\n",
    "            i = checked_words.index(cur_word)\n",
    "            f_connections[i].append(f_moves[f])\n",
    "            p_connections[i].append(p_moves[f])\n",
    "    #    print(len(checked_words),len(unchecked_words))\n",
    "    return checked_words, e_connections, f_connections, p_connections    \n",
    "\n",
    "def dfs(node, connections, nodes_visited,component, words): #Needs work\n",
    "    for v in connections[node]:\n",
    "        index = words.index(v)\n",
    "        if nodes_visited[index] == False:\n",
    "            nodes_visited[index] = True\n",
    "            component.append(index)\n",
    "            component, nodes_visited = dfs(index,connections, nodes_visited, component,words)\n",
    "    return component, nodes_visited\n",
    "\n",
    "def find_component_flips(words, component, components, p_flips,packets):\n",
    "    c_flips = {words.index(p_flips[n][x]): packets[n][x] for n in component for x in range(0,len(p_flips[n]))}\n",
    "    c_flips_comp = {}\n",
    "    for x in c_flips:\n",
    "        x_in_comp = None\n",
    "        for y in range(0,len(components)):\n",
    "            if x in components[y]:\n",
    "                x_in_comp = y\n",
    "        if x_in_comp not in c_flips_comp:\n",
    "            c_flips_comp[x_in_comp] = [c_flips[x]]\n",
    "        else:\n",
    "            c_flips_comp[x_in_comp].append(c_flips[x])        \n",
    "    return c_flips_comp\n",
    "    \n",
    "\n",
    "def shrink_equivalences(words, equivalences, packet_flips,packets): #Needs work\n",
    "    visited = {i: False for i in range(0,len(words))}\n",
    "    e_components = []\n",
    "    for i in range(0,len(words)):\n",
    "        if visited[i] == False:\n",
    "            visited[i] = True\n",
    "            e_component = [i]\n",
    "            e_component, visited = dfs(i, equivalences,visited,e_component,words)\n",
    "            e_components.append(e_component)\n",
    "    component_flips = {i: find_component_flips(words, e_components[i],e_components,packet_flips,packets) \n",
    "                       for i in range(0,len(e_components))}    \n",
    "    return e_components, component_flips\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_up(topexp, elt,one_packets,two_packets):\n",
    "    return ((np.sum([len(good_in_packet(x,elt,one_packets,two_packets))>0 for x in topexp])) == 0)\n",
    "\n",
    "#Tries to bubble down the first word given by expression[indices]\n",
    "#returns a new expression with the first word bubbled down as far as it will go (up until the final index in indices)\n",
    "#returns successful = True if first word is bubbled below the end index\n",
    "def bubble_down(packet, head_elt, subexp,one_packets,two_packets):\n",
    "    bubbled = False\n",
    "    cur_pos = 0\n",
    "    end_pos = len(subexp) - 1\n",
    "    while cur_pos < end_pos:\n",
    "        #print('The head element is {}. And the subexpression is {}'.format(head_elt, subexp))\n",
    "        #print('This is the current position {}. This is the end position {}'.format(cur_pos,end_pos))\n",
    "        next_pos = cur_pos + 1\n",
    "        next_elt = subexp[next_pos]\n",
    "        if move_up([head_elt], next_elt,one_packets,two_packets):\n",
    "            subexp = flip(subexp,[cur_pos, next_pos])\n",
    "            cur_pos += 1\n",
    "            if next_elt == packet[-1]:\n",
    "                end_pos -= 1\n",
    "            #print('The head element successfully moved down past {}\\n'.format(next_elt))\n",
    "            continue\n",
    "        else:\n",
    "            if next_elt in packet:\n",
    "                #print('The head element is blocked by the packet element {}. \\nThe head_elt is: {} The next elt is {}\\n'.format(head_elt,next_elt, subexp))\n",
    "                return False, subexp\n",
    "            else:\n",
    "                #print('The head element is blocked by a non-packet element.\\n Head element is {}. And next_elt is {}\\n'.format(head_elt, next_elt))\n",
    "                bubbled, subsubexp = bubble_down(packet, next_elt, subexp[next_pos:end_pos+1],one_packets,two_packets)\n",
    "                subexp[next_pos:end_pos+1] = subsubexp\n",
    "                if bubbled == True:\n",
    "                    end_pos -=1\n",
    "                else:\n",
    "                    return False, subexp\n",
    "    return True, subexp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes in a subexpression and a packet\n",
    "#tells you if the packet can be brought together via equivalences\n",
    "#if you can then it will return the new word\n",
    "#At the start exp begins with the first element in packet and ends with the last element in packet\n",
    "def come_together(exp, packet,one_packets, two_packets):\n",
    "   # print(exp, packet)\n",
    "    assert(len(exp) >= len(packet)),'Your packet is bigger than the expression'\n",
    "    pointer = 0 #<--- Keeps track of the leading packet element that has been encountered\n",
    "    cur_pos = 0 #<--- Keeps track of where the head_packet_elt is\n",
    "    end_pos = len(exp) - 1 #<--- Keeps track of where the last packet element is in the expression\n",
    "    \n",
    "    if len(exp) == len(packet):\n",
    "    #    print('This is your expression {}\\nThis is your packet {}'.format(exp,packet))\n",
    "    #    print('The packet is flippable')\n",
    "        return True, exp, end_pos\n",
    "    \n",
    "    while True:\n",
    "    #    print('This is your expression {}\\nThis is your packet {}'.format(exp,packet))\n",
    "    #    print('This is the end position {}\\nThis is the current position {}\\nThis is the pointer {}'.format(\n",
    "    #        end_pos, cur_pos, pointer, len(packet)))\n",
    "        if (end_pos - (cur_pos - pointer)) + 1 == len(packet): #So the packet has been brought together\n",
    "    #        print('Your packet has been brought together. This is the end position {} and this is the start position {}'.format(end_pos, cur_pos))\n",
    "            break\n",
    "        next_pos = cur_pos + 1\n",
    "        next_elt = exp[next_pos]\n",
    "    #    print(cur_pos, next_pos)\n",
    "        if next_elt in packet:\n",
    "            pointer += 1\n",
    "            cur_pos += 1\n",
    "            #if cur_pos == end_pos-1:\n",
    "            #    print('Your packet has been brought together. This is the end position {} and this is the start position {}'.format(\n",
    "            #    end_pos, cur_pos))\n",
    "            continue\n",
    "        else:\n",
    "            if move_up(packet[:pointer+1], next_elt,one_packets, two_packets) == True: #y can be moved above the packet elements above it\n",
    "                del exp[next_pos]\n",
    "                exp.insert(cur_pos-pointer,next_elt) #This was wrong. You don't always move up all the way. Just before the seen packet elements\n",
    "                cur_pos += 1\n",
    "                continue\n",
    "            else: #so y can't be bubbled up, let's try bubbling it down\n",
    "    #            print('You cannot bubble up {} from {}'.format(next_elt, exp))\n",
    "                bubbled, subexp = bubble_down(packet, next_elt, exp[next_pos:end_pos+1],one_packets,two_packets)\n",
    "                if bubbled == True:\n",
    "    #                print('You successfully bubbled {} out of {}'.format(next_elt, exp))\n",
    "                    exp[next_pos:end_pos+1] = subexp\n",
    "                    end_pos = exp.index(packet[-1]) \n",
    "    #                print('The new end position is {}\\nThe new expression is {}'.format(end_pos,exp))\n",
    "    #                print('The pointer is {} and the current position is {}'.format(pointer, cur_pos))\n",
    "    #                print('The gap is {}'.format(end_pos - (cur_pos - pointer)))\n",
    "                    continue\n",
    "                else:\n",
    "                    return False, exp, end_pos\n",
    "    return True, exp, end_pos\n",
    "                \n",
    "                \n",
    "#one_packets and two_packets are dictionaries containing the k+1 sets along with the \n",
    "#consecutive pairings of k-sets in the packet when ordered in the lex order\n",
    "def find_exp_node_flips(expression, one_packets, two_packets):\n",
    "    next_words = {}\n",
    "    split_pairs = []\n",
    "    for p in one_packets: #Should also check if p is in order\n",
    "        skip = False\n",
    "        for x in one_packets[p]:\n",
    "            if x in split_pairs:\n",
    "                skip = True\n",
    "                continue\n",
    "        if skip == True:\n",
    "            continue\n",
    "        else:\n",
    "            packet = one_packets[p]\n",
    "            indices = [expression.index(x) for x in packet]\n",
    "            if sorted(indices) != indices:\n",
    "                skip == True\n",
    "                continue\n",
    "            #print('This is the expression: {}\\nThis is the packet: {}\\nHere are the indices {}'.format(\n",
    "            #    expression, packet, indices))\n",
    "            #print('The packet has length {}'.format(len(packet)))\n",
    "            #print('The subexpression is {}'.format(expression[indices[0]:indices[-1]+1]))\n",
    "            brought_together, exp, end_pos = come_together(expression[indices[0]:indices[-1]+1],packet, one_packets, two_packets)\n",
    "            if brought_together == True:\n",
    "                exp = flip(exp,[end_pos - len(packet) +1,end_pos])\n",
    "                next_exp = expression.copy()\n",
    "                next_exp[indices[0]:indices[-1]+1] = exp\n",
    "            #    print('The packet was flipped\\n')\n",
    "                next_words[p] = next_exp\n",
    "            else:\n",
    "                #print('The packet was not flipped\\n')\n",
    "                pass\n",
    "    for p in two_packets:\n",
    "        skip = False\n",
    "        for x in two_packets[p]:\n",
    "            if x in split_pairs:\n",
    "                skip = True\n",
    "                continue\n",
    "        if skip == True:\n",
    "            continue\n",
    "        else:\n",
    "            packet = two_packets[p]\n",
    "            indices = [expression.index(x) for x in packet]\n",
    "            if sorted(indices) != indices:\n",
    "                skip == True\n",
    "                continue\n",
    "            #print('This is the expression: {}\\nThis is the packet: {}\\nHere are the indices {}'.format(\n",
    "            #   expression, packet, indices))\n",
    "            #print('The packet has length {}'.format(len(packet)))\n",
    "            #print('The subexpression is {}'.format(expression[indices[0]:indices[-1]+1]))\n",
    "            brought_together, exp, end_pos = come_together(expression[indices[0]:indices[-1]+1],packet, one_packets, two_packets)\n",
    "            if brought_together == True:\n",
    "                exp = flip(exp,[end_pos - len(packet) +1,end_pos])\n",
    "                next_exp = expression.copy()\n",
    "                next_exp[indices[0]:indices[-1]+1] = exp\n",
    "                #print('The packet was flipped\\n')\n",
    "                next_words[p] = next_exp\n",
    "            else:\n",
    "                #print('The packet was not flipped\\n')\n",
    "                pass\n",
    "    return next_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checks if the cur_word's history has been seen before.\n",
    "#If it has, then it returns the node with the same history\n",
    "#cur_word_hist: list of tuples\n",
    "#checked_hist: dictionary whose index is the level (path length) and entries are a [[node1:[tuples]],[node2: [tuples1],[tuples2]]]\n",
    "def check_history(cur_word_hist, checked_hist):\n",
    "    cur_level = len(cur_word_hist[0])\n",
    "    cur_word_hist = set(cur_word_hist[0])\n",
    "    tracker = 0\n",
    "    if cur_level not in checked_hist.keys():\n",
    "        return False, -1\n",
    "    \n",
    "#     print(cur_level, cur_word_hist)\n",
    "    \n",
    "    for i in checked_hist[cur_level]:\n",
    "        check_set = set(i)\n",
    "#         print(check_set)\n",
    "        if cur_word_hist == check_set:\n",
    "            spot = np.sum([len(checked_hist[j]) for j in range(0,cur_level)]) + tracker + 1\n",
    "            return True, spot\n",
    "        tracker += 1\n",
    "    return False, -1\n",
    "\n",
    "def build_p_history(word, word_p_hist, total_p_hist, parent_node):\n",
    "    history = [x.copy() for x in total_p_hist[parent_node].copy()]\n",
    "    history = [x + [word_p_hist] for x in history]\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deprecated\n",
    "def quick_build_graph(type_one_n_sets, type_two_n_sets, start_word, add_flips = True):\n",
    "    cur_level = 0\n",
    "    level_starts = {0: 0}\n",
    "    checked_words = [start_word]\n",
    "    unchecked_words = []\n",
    "    f_connections = {0: []}\n",
    "    p_connections = {0: []}\n",
    "    p_history = {0: []}\n",
    "    n_connections = {0: []}\n",
    "    n_history = {0: []}\n",
    "    \n",
    "    connections = find_exp_node_flips(start_word,type_one_n_sets, type_two_n_sets)\n",
    "    f_moves = [connections[w] for w in connections]\n",
    "    p_moves = list(connections.keys())\n",
    "    for f in range(0,len(f_moves)):\n",
    "        #if (f_moves[f] not in unchecked_words) and (add_flips == True):\n",
    "        unchecked_words.append(f_moves[f])\n",
    "        i = len(checked_words) + len(unchecked_words) - 1\n",
    "        f_connections[i] = []\n",
    "        p_connections[i] = []\n",
    "        n_connections[i] = []\n",
    "        n_history[i] = [len(checked_words) - 1]\n",
    "        p_history[i] = [p_moves[f]]             \n",
    "        j = len(checked_words) - 1\n",
    "        f_connections[j].append(f_moves[f])\n",
    "        p_connections[j].append(p_moves[f])\n",
    "        n_connections[j].append(i)\n",
    "    cur_level += 1\n",
    "    level_starts[1] = 1\n",
    "    while len(unchecked_words) != 0:\n",
    "        cur_word = unchecked_words.pop(0)\n",
    "        checked_words.append(cur_word)\n",
    "        connections = find_exp_node_flips(cur_word,type_one_n_sets, type_two_n_sets)\n",
    "        f_moves = [connections[w] for w in connections]\n",
    "        p_moves = list(connections.keys())\n",
    "        for f in range(0,len(f_moves)):\n",
    "           # if (f_moves[f] not in unchecked_words) and (f_moves[f] not in checked_words) and (add_flips == True):\n",
    "            unchecked_words.append(f_moves[f])\n",
    "            i = len(checked_words) + len(unchecked_words) - 1\n",
    "            f_connections[i] = []\n",
    "            p_connections[i] = []\n",
    "            n_connections[i] = []\n",
    "            n_history[i] = n_history[len(checked_words) - 1].copy()\n",
    "            n_history[i].append(len(checked_words) - 1)\n",
    "            p_history[i] = p_history[len(checked_words) - 1].copy()\n",
    "            p_history[i].append(p_moves[f])\n",
    "            j = checked_words.index(cur_word)\n",
    "            f_connections[j].append(f_moves[f])\n",
    "            p_connections[j].append(p_moves[f])\n",
    "            n_connections[j].append(i)\n",
    "    return checked_words, f_connections, p_connections, p_history, n_connections, n_history\n",
    "\n",
    "#Current workhorse\n",
    "#One_path is used to select a single starting branch to build out. It should be the first packet flipped in the branch that\n",
    "#you want to build <--- Not fully built. Right now it just works with one_path = [-5,-4,-3,-2]\n",
    "def build_condensed_graph(type_one_n_sets, type_two_n_sets, start_word, one_path, max_branches = 100, add_flips = True):\n",
    "    #print(one_path)\n",
    "    count = 0\n",
    "    checked_words = [start_word]\n",
    "    unchecked_words = []\n",
    "    checked_history = {0: []}\n",
    "    f_connections = {0: []}\n",
    "    p_connections = {0: []}\n",
    "    p_history = {0: []}\n",
    "    n_connections = {0: []}\n",
    "    n_history = {0: []}\n",
    "    equiv_words = {}\n",
    "    \n",
    "    connections = find_exp_node_flips(start_word,type_one_n_sets, type_two_n_sets)\n",
    "    f_moves = [connections[w] for w in connections]\n",
    "    p_moves = list(connections.keys())\n",
    "    for f in range(0,min(len(f_moves),max_branches)): #should be len(f_moves) but trying 3\n",
    "        level = 1\n",
    "        unchecked_words.append(f_moves[f])\n",
    "        i = len(checked_words) + len(unchecked_words) - 1\n",
    "        f_connections[i] = []\n",
    "        p_connections[i] = []\n",
    "        n_connections[i] = []\n",
    "        n_history[i] = [[len(checked_words) - 1]]\n",
    "        p_history[i] = [[p_moves[f]]]             \n",
    "        j = len(checked_words) - 1\n",
    "        f_connections[j].append(f_moves[f])\n",
    "        p_connections[j].append(p_moves[f])\n",
    "        n_connections[j].append(i)\n",
    "        if level in checked_history.keys():\n",
    "             checked_history[level].append(p_history[i][0])\n",
    "        else:\n",
    "             checked_history[level] = [p_history[i][0]]\n",
    "        if one_path == True:\n",
    "            break\n",
    "    while len(unchecked_words) != 0:\n",
    "        print(count)\n",
    "        cur_word = unchecked_words.pop(0)\n",
    "        checked_words.append(cur_word)\n",
    "        add_node_num = len(checked_words) - 1\n",
    "        if count > 500:\n",
    "            break\n",
    "        else:\n",
    "            connections = find_exp_node_flips(cur_word,type_one_n_sets, type_two_n_sets)\n",
    "            f_moves = [connections[w] for w in connections]\n",
    "            p_moves = list(connections.keys())\n",
    "            l = len(f_moves)\n",
    "            for f in range(0,min(len(f_moves),max_branches)):#should be len(f_moves) changed to 3 to see if you can get good data\n",
    "                poss_word = f_moves[f]\n",
    "                poss_p_history = build_p_history(poss_word, p_moves[f], p_history, add_node_num)\n",
    "                level = len(poss_p_history[0])\n",
    "                found, index = check_history(poss_p_history, checked_history)\n",
    "                #Almost there. Just need to actually use check_history\n",
    "                if found == False:\n",
    "                    #print(\"The word has not been seen yet. Checked history returned: {}\".format(found))\n",
    "                    unchecked_words.append(poss_word)\n",
    "                    i = len(checked_words) + len(unchecked_words) - 1\n",
    "                    f_connections[i] = []\n",
    "                    p_connections[i] = []\n",
    "                    n_connections[i] = []\n",
    "                    n_history[i] = [x.copy() for x in n_history[add_node_num].copy()]\n",
    "                    n_history[i] = [x+[add_node_num] for x in n_history[i]]\n",
    "                    p_history[i] = poss_p_history\n",
    "                    j = add_node_num #checked_words.index(cur_word)\n",
    "                    f_connections[j].append(poss_word)\n",
    "                    p_connections[j].append(p_moves[f])\n",
    "                    n_connections[j].append(i)\n",
    "                    if level in checked_history.keys():\n",
    "                        checked_history[level].append(poss_p_history[0])\n",
    "                    else:\n",
    "                        checked_history[level] = [poss_p_history[0]]\n",
    "#             if poss_word not in unchecked_words:\n",
    "#                 print(\"The word has not been seen yet. Checked history returned: {}\".format(found))\n",
    "#                 unchecked_words.append(poss_word)\n",
    "#                 i = len(checked_words) + len(unchecked_words) - 1\n",
    "#                 f_connections[i] = []\n",
    "#                 p_connections[i] = []\n",
    "#                 n_connections[i] = []\n",
    "#                 n_history[i] = [x.copy() for x in n_history[add_node_num].copy()]\n",
    "#                 n_history[i] = [x+[add_node_num] for x in n_history[i]]\n",
    "#                 p_history[i] = poss_p_history\n",
    "#                 j = add_node_num #checked_words.index(cur_word)\n",
    "#                 f_connections[j].append(poss_word)\n",
    "#                 p_connections[j].append(p_moves[f])\n",
    "#                 n_connections[j].append(i)\n",
    "#                 if level in checked_history.keys():\n",
    "#                     checked_history[level].append(poss_p_history[0])\n",
    "#                 else:\n",
    "#                     checked_history[level] = [poss_p_history[0]]\n",
    "                else:\n",
    "                    #print(\"The word has been seen already. Checked history returned: {}\".format(found))\n",
    "#                      index = unchecked_words.index(f_moves[f]) + len(checked_words)\n",
    "                    history = n_history[add_node_num].copy()\n",
    "                    history = [x.copy() for x in history]\n",
    "                    history = [x+[add_node_num] for x in history]\n",
    "                    for r in history:\n",
    "                        n_history[index].append(r)\n",
    "                    history = p_history[add_node_num].copy()\n",
    "                    history = [x.copy() for x in history]\n",
    "                    history = [r+[p_moves[f]] for r in history]\n",
    "                    for r in history:\n",
    "                        p_history[index].append(r)\n",
    "                    j = add_node_num\n",
    "                    f_connections[j].append(f_moves[f])\n",
    "                    p_connections[j].append(p_moves[f])\n",
    "                    n_connections[j].append(index)\n",
    "        count += 1\n",
    "    #print(checked_history)\n",
    "    return checked_words, f_connections, p_connections, p_history, n_connections, n_history\n",
    " \n",
    "def get_packets_dict(J,k):\n",
    "    if k + 1<= max(J):\n",
    "        one_sets = [list(a) for a in type_one_sets(J,k+1)]\n",
    "        one_packets = {}\n",
    "        for a in one_sets:\n",
    "            packets = get_packet(list(a),len(a)-1)\n",
    "            one_packets[tuple(a)] = [list(x) for x in packets]\n",
    "    else:\n",
    "        one_packets = {}\n",
    "    \n",
    "    two_sets = [list(a) for a in type_two_sets(J,k+1)]\n",
    "    two_packets = {}\n",
    "   \n",
    "    for a in two_sets:\n",
    "        s = np.array(list(a))\n",
    "        s.sort()\n",
    "        packets = get_packet(s, len(s)-1)\n",
    "        two_packets[tuple(s)] = [list(x) for x in packets]\n",
    "    return one_packets, two_packets\n",
    "\n",
    "def generate_graph(J,k, one_path, max_branches, condensed = True):\n",
    "    lex_word = [list(x) for x in all_sets(J,k)]\n",
    "    one_packets, two_packets = get_packets_dict(J,k)       \n",
    "    if condensed == True:\n",
    "        graph = build_condensed_graph(one_packets, two_packets, lex_word, one_path, max_branches)\n",
    "    else:\n",
    "        graph = quick_build_graph(one_packets,two_packets,lex_word)\n",
    "    return graph\n",
    "\n",
    "#Collapse nodes that have the same packet flip history\n",
    "def collapse_graph(graph):\n",
    "    nice_graph = {}\n",
    "    level_start_pts = {0: 0}\n",
    "    unique_nodes = {0: [0]}\n",
    "    cur_level = 0 \n",
    "    for i in range(1,len(graph[0])):\n",
    "        n_history_set = graph[-1][i]\n",
    "        p_history_set = set(graph[3][i])\n",
    "        level = len(n_history_set)\n",
    "        if level > cur_level:\n",
    "            cur_level += 1\n",
    "            level_start_pts[cur_level] = i\n",
    "            unique_nodes[i] = [i] \n",
    "        else:\n",
    "            unique = True\n",
    "            for j in range(level_start_pts[cur_level],i):\n",
    "                other_p_history_set = set(graph[3][j])\n",
    "                if p_history_set == other_p_history_set:\n",
    "                    unique_nodes[j].append(i)\n",
    "                    unique = False\n",
    "                    break\n",
    "            if unique == True:\n",
    "                unique_nodes[i] = [i]\n",
    "    return unique_nodes\n",
    "                \n",
    "            \n",
    "            \n",
    "        \n",
    "\n",
    "#Used to better visualize the output of quick_build_graph\n",
    "def visualize_graph(graph, forward, packets, output = None):\n",
    "    if output != None:\n",
    "        file = open(output, 'w')\n",
    "    level = 0\n",
    "    counter = 0\n",
    "    if forward == True:\n",
    "        n = 4\n",
    "        p = 2\n",
    "    else:\n",
    "        n = 5\n",
    "        p = 3\n",
    "    if output != None:\n",
    "        file.write('Here are the level 0 nodes: \\n')\n",
    "    else:\n",
    "        print('Here are the level 0 nodes: ')\n",
    "    for i in graph[-1]:\n",
    "        n_history_set = graph[n][i]\n",
    "        p_history_set = graph[p][i]\n",
    "        if i != 0:\n",
    "            if len(graph[3][i][-1]) > level:\n",
    "                level += 1\n",
    "                if output != None:\n",
    "                    file.write('There were {} level {} nodes.\\n \\nHere are the level {} nodes\\n'.format(counter, level -1, level))\n",
    "                else:\n",
    "                    print('There were {} level {} nodes.\\n \\nHere are the level {} nodes'.format(counter, level -1, level))\n",
    "                counter = 0\n",
    "        if output != None:\n",
    "            file.write(\"{}: {}\\n\".format(i,n_history_set))\n",
    "        else:\n",
    "            print(\"{}: {}\".format(i,n_history_set))\n",
    "        if packets == True:\n",
    "            if output != None:\n",
    "                file.write(\"{}: {}\\n\".format(i, p_history_set))\n",
    "            else:\n",
    "                print(\"{}: {}\".format(i, p_history_set))\n",
    "        counter += 1\n",
    "    if output != None:\n",
    "        file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_non_commuting_squares(graph,one_packets, two_packets):\n",
    "    for x in graph[2]:\n",
    "        for i in range(0,len(graph[2][x])-1):\n",
    "            x_word = graph[2][x][i]\n",
    "            for j in range(i+1,len(graph[2][x])):\n",
    "                y_word = graph[2][x][j]\n",
    "                if len(good_in_packet(one_packets = one_packets, two_packets = two_packets, x = x_word, y = y_word))!=0:\n",
    "                    node_x = graph[-2][x][i]\n",
    "                    node_y = graph[-2][x][j]\n",
    "                    if x_word in graph[2][node_y] and y_word in graph[2][node_x]:\n",
    "                        print('You found a non-commuting square off of word {}.\\nIt points to the following nodes {} and {}.\\nIt involved the following packets:\\n {}\\n {}'.format(\n",
    "                          x,node_x,node_y,x_word,y_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#B_4 k = 3 Playground\n",
    "n = 4\n",
    "k = 3\n",
    "J = [-4,-3,-2,-1,1,2,3,4]\n",
    "k_4_3_graph = generate_graph(J,k,one_path = False, max_branches = 10)\n",
    "one_packets, two_packets = get_packets_dict(J,k+1)\n",
    "#find_non_commuting_squares(k_4_3_graph,one_packets = {}, two_packets = two_packets)\n",
    "#two_packets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the level 0 nodes: \n",
      "0: [1, 2, 3]\n",
      "0: [(-4, -3, -2, -1), (-4, -1, 3, 2), (-3, -2, -1, 1)]\n",
      "There were 1 level 0 nodes.\n",
      " \n",
      "Here are the level 1 nodes\n",
      "1: [4]\n",
      "1: [(-4, -1, 3, 2)]\n",
      "2: [4]\n",
      "2: [(-4, -3, -2, -1)]\n",
      "3: [5, 6]\n",
      "3: [(-4, -2, -1, 3), (-4, 3, 2, 1)]\n",
      "There were 3 level 1 nodes.\n",
      " \n",
      "Here are the level 2 nodes\n",
      "4: [7]\n",
      "4: [(-4, -3, -2, 2)]\n",
      "5: [8]\n",
      "5: [(-4, 3, 2, 1)]\n",
      "6: [8]\n",
      "6: [(-4, -2, -1, 3)]\n",
      "There were 3 level 2 nodes.\n",
      " \n",
      "Here are the level 3 nodes\n",
      "7: [9]\n",
      "7: [(-4, -3, -2, 1)]\n",
      "8: [10]\n",
      "8: [(-4, -2, -1, 1)]\n",
      "There were 2 level 3 nodes.\n",
      " \n",
      "Here are the level 4 nodes\n",
      "9: [11]\n",
      "9: [(-4, -3, -1, 2)]\n",
      "10: [12, 13]\n",
      "10: [(-4, -3, 2, 1), (-4, -2, 3, 1)]\n",
      "There were 2 level 4 nodes.\n",
      " \n",
      "Here are the level 5 nodes\n",
      "11: [14]\n",
      "11: [(-4, -3, -1, 1)]\n",
      "12: [15]\n",
      "12: [(-4, -2, 3, 1)]\n",
      "13: [15]\n",
      "13: [(-4, -3, 2, 1)]\n",
      "There were 3 level 5 nodes.\n",
      " \n",
      "Here are the level 6 nodes\n",
      "14: [16, 17]\n",
      "14: [(-4, -3, 2, 1), (-4, -2, 3, 1)]\n",
      "15: [18]\n",
      "15: [(-4, -3, -1, 1)]\n",
      "There were 2 level 6 nodes.\n",
      " \n",
      "Here are the level 7 nodes\n",
      "16: [19]\n",
      "16: [(-4, -2, 3, 1)]\n",
      "17: [19]\n",
      "17: [(-4, -3, 2, 1)]\n",
      "18: [20]\n",
      "18: [(-4, -3, -1, 2)]\n",
      "There were 3 level 7 nodes.\n",
      " \n",
      "Here are the level 8 nodes\n",
      "19: [21]\n",
      "19: [(-4, -2, -1, 1)]\n",
      "20: [22]\n",
      "20: [(-4, -3, -2, 1)]\n",
      "There were 2 level 8 nodes.\n",
      " \n",
      "Here are the level 9 nodes\n",
      "21: [23, 24]\n",
      "21: [(-4, -2, -1, 3), (-4, 3, 2, 1)]\n",
      "22: [25]\n",
      "22: [(-4, -3, -2, 2)]\n",
      "There were 2 level 9 nodes.\n",
      " \n",
      "Here are the level 10 nodes\n",
      "23: [26]\n",
      "23: [(-4, 3, 2, 1)]\n",
      "24: [26]\n",
      "24: [(-4, -2, -1, 3)]\n",
      "25: [27, 28]\n",
      "25: [(-4, -3, -2, -1), (-4, -1, 3, 2)]\n",
      "There were 3 level 10 nodes.\n",
      " \n",
      "Here are the level 11 nodes\n",
      "26: [29]\n",
      "26: [(-3, -2, -1, 1)]\n",
      "27: [29]\n",
      "27: [(-4, -1, 3, 2)]\n",
      "28: [29]\n",
      "28: [(-4, -3, -2, -1)]\n",
      "There were 3 level 11 nodes.\n",
      " \n",
      "Here are the level 12 nodes\n",
      "29: []\n",
      "29: []\n"
     ]
    }
   ],
   "source": [
    "#Work with B_4 k = 3 graph\n",
    "visualize_graph(k_4_3_graph, forward = True, packets = True, output = None )# 'B_4_K_3_All_Paths_Backwards_Packets.txt')\n",
    "#for x in k_3_graph[3]:\n",
    "#    print(k_3_graph[3][x])\n",
    "# lex_word = [list(x) for x in k_3_graph[3][12][0]]\n",
    "# one_packets, two_packets = get_packets_dict(J,k)\n",
    "# bubble_down(packet = [[-4,-1,3,2]], head_elt = [-4,-1,3,2], subexp = lex_word[1:], one_packets = one_packets, two_packets = two_packets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#B_4 k = 2 Playground\n",
    "n = 4\n",
    "k = 2\n",
    "J = [i for i in range(-n,n+1) if i != 0]\n",
    "J = [-4,-3,-2,-1,1,2,3,4]\n",
    "#k_4_2_graph = generate_graph(J,k, one_path = False, max_branches = 100)\n",
    "#visualize_graph(k_4_2_graph, packets = True, forward = True, output = 'B_4_K_2_All_Path_Forwards_Packets.txt')\n",
    "\n",
    "# lex_word = [list(x) for x in k_4_2_graph[3][21][0]]\n",
    "one_packets, two_packets = get_packets_dict(J,k+1)\n",
    "one_sets, two_sets = [x for x in one_packets.keys()],[x for x in two_packets.keys()]\n",
    "# packets_containing(type_one_n_sets = one_sets, type_two_n_sets = two_sets, word = [-4,3,2])\n",
    "# come_together(exp = lex_word[0:17], packet = [[-4,-3,-2],[-4,3,2]], one_packets = one_packets, two_packets = two_packets)\n",
    "\n",
    "find_non_commuting_squares(k_4_2_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "#B_3 k = 2 Playground\n",
    "n = 3\n",
    "k = 2\n",
    "J = [i for i in range(-n,n+1) if i != 0]\n",
    "k_2_graph = generate_graph(J,k,one_path = False, max_branches = 100)\n",
    "visualize_graph(k_2_graph, forward = True, packets = True, output = 'B_3_K_2_All_Paths_Forwards_Packets.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#B_2 k = 2 Testing Grounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "#B_5 playground k = 3\n",
    "n = 5\n",
    "k = 3\n",
    "J = [i for i in range(-n,n+1) if i != 0]\n",
    "k_5_3_graph = generate_graph(J,k, one_path = False, max_branches = 1)\n",
    "one_sets = type_one_sets(J,k+1)\n",
    "two_sets = type_two_sets(J,k+1)\n",
    "one_packets = {}\n",
    "two_packets = {}\n",
    "\n",
    "for a in one_sets:\n",
    "    packets = get_packet(list(a),len(a)-1)\n",
    "    one_packets[tuple(a)] = [list(x) for x in packets]\n",
    "    \n",
    "for a in two_sets:\n",
    "    s = np.array(list(a))\n",
    "    s.sort()\n",
    "    packets = get_packet(s, len(s)-1)\n",
    "    two_packets[tuple(s)] = [list(x) for x in packets]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#B_5 k = 3 Testing Ground\n",
    "# lex_word = [list(x) for x in all_sets(J,k,sort = True)]\n",
    "# visualize_graph(k_5_3_graph, forward = True, packets = True, output = 'B_5_K_3_One_Path_End.txt')\n",
    "#len(type_one_sets(J,k))+len(type_two_sets(J,k))\n",
    "#good_in_packet([-5,-4,-3,-2],[-5,-1,4,3],one_packets,two_packets)\n",
    "# moves = find_exp_node_flips(lex_word, get_packets_dict(J,k)[0], get_packets_dict(J,k)[1])\n",
    "# moves\n",
    "#packet = (-5,-3,-2,-1)\n",
    "#word = moves[packet]\n",
    "#word\n",
    "#exp = lex_word[0:7]\n",
    "#print(packet)\n",
    "#come_together(lex_word[0:7],one_packets[(-5,-4,-3,-2)],one_packets, two_packets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "#B_5 k = 4 Playground\n",
    "J = 5\n",
    "k = 4\n",
    "lex_word = [list(x) for x in k_5_3_graph[3][50][0]]\n",
    "lex_word[7] = [-4,-1,3,2]\n",
    "lex_word[8] = [-5,-1,3,2]\n",
    "lex_word[9] = [-4,-3,-2,-1]\n",
    "# i = lex_word.index([-4,-3,-2,-1])\n",
    "# j = lex_word.index([-4,-1,3,2])\n",
    "# print(j)\n",
    "J = [i for i in range(-n,n+1) if i != 0]\n",
    "one_sets = type_one_sets(J,k+1)\n",
    "two_sets = [list(a) for a in type_two_sets(J,k+1)]\n",
    "one_packets = {}\n",
    "two_packets = {}\n",
    "\n",
    "for a in one_sets:\n",
    "    packets = get_packet(list(a),len(a)-1)\n",
    "    packets = [list(x) for x in packets]\n",
    "    one_packets[tuple(a)] = merge_sort(packets,hard_order = lex_word)   \n",
    "for a in two_sets:\n",
    "    s = np.array(list(a))\n",
    "    s.sort()\n",
    "    packets = get_packet(s, len(s)-1)\n",
    "    packets = [list(x) for x in packets]\n",
    "    two_packets[tuple(s)] = merge_sort(packets, hard_order = lex_word)\n",
    "k_5_4_graph = build_condensed_graph(one_packets, two_packets, lex_word, one_path = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# moves = find_exp_node_flips(lex_word, one_packets, two_packets)\n",
    "# moves\n",
    "# print(one_packets[(-5,-4,-1,3,2)])\n",
    "# print(one_packets[(-5,4,3,2,1)])\n",
    "# anti_lex_word = [list(x) for x in k_5_4_graph[3][46][-1]]\n",
    "# anti_lex_word\n",
    "# two_packets[(-4,-3,-2,-1,1)]\n",
    "#packet = (-5,-4,-1,3,2)\n",
    "#packet_full = one_packets[packet]\n",
    "#packet_full\n",
    "#word = moves[packet]\n",
    "visualize_graph(k_5_4_graph, forward = True, packets = True, output = 'B_5_K_4_All_Paths_Forwards_Packets_Double_Swapped_Lex.txt')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#####Used to get a trial lex\n",
    "# w = k_5_4_graph[0][-1]\n",
    "# new_lex = [w[len(w) - x] for x in range(1,len(w)+1)]\n",
    "# new_lex\n",
    "# file = open('New_4_set_lex.txt', 'w')\n",
    "# for x in new_lex:\n",
    "#     file.write(str(x)+\"\\n\")\n",
    "\n",
    "# file.close()\n",
    "#come_together([list(x) for x in word[8:19]],packet_full, one_packets, two_packets)\n",
    "#come_together(lex_word[0:8],packet_full, one_packets, two_packets)\n",
    "#print(len(one_packets)+len(two_packets)) \n",
    "#visualize_graph(graph, forward = True, packets = True, output = 'B_5_K_4_All_Paths_Forwards_Packets.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#B_6 playground k = 3\n",
    "# n = 6\n",
    "# k = 3\n",
    "# J = [i for i in range(-n,n+1) if i != 0]\n",
    "# k_6_3_graph = generate_graph(J,k, one_path = True)\n",
    "# one_sets = type_one_sets(J,k+1)\n",
    "# two_sets = type_two_sets(J,k+1)\n",
    "# one_packets = {}\n",
    "# two_packets = {}\n",
    "\n",
    "# for a in one_sets:\n",
    "#     packets = get_packet(list(a),len(a)-1)\n",
    "#     one_packets[tuple(a)] = [list(x) for x in packets]\n",
    "    \n",
    "# for a in two_sets:\n",
    "#     s = np.array(list(a))\n",
    "#     s.sort()\n",
    "#     packets = get_packet(s, len(s)-1)\n",
    "#     two_packets[tuple(s)] = [list(x) for x in packets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#B_6 k = 3 Testing Ground\n",
    "#visualize_graph(k_5_3_graph, packets = True)\n",
    "#len(type_one_sets(J,k))+len(type_two_sets(J,k))\n",
    "#good_in_packet([-5,-4,-3,-2],[-5,-1,4,3],one_packets,two_packets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #In Packet Test cases! GOOD\n",
    "# # < k - 2 test cases - Never in Packet GOOD\n",
    "# test_1 = np.array([-7,-6,-5,-4])\n",
    "# test_2 = np.array([-4,-3,-2,-1])\n",
    "# #print(in_packet(test_1,test_2)) \n",
    "# # = k - 2 test cases GOOD\n",
    "#     #Both Type 1 - Never in Packet GOOD\n",
    "# test_3 = test_1\n",
    "# test_4 = np.array([-7,-6,-3,-2])\n",
    "# # print(in_packet(test_3,test_4))\n",
    "#     #Type 1 with Type 2 - Never In Packet\n",
    "#         #No Star Overlap - Not In GOOD\n",
    "# test_5 = test_1\n",
    "# test_6 = np.array([-7,-6,-3,3])\n",
    "# # print(in_packet(test_5,test_6))\n",
    "#         #Star Overlap - Not in - GOOD\n",
    "# test_7 = np.array([-7,-6,-5,2])\n",
    "# test_8 = np.array([-5,-3,-2,2])\n",
    "# # print(in_packet(test_7,test_8))\n",
    "#     #Type 2 with Type 2 - Always in Packet\n",
    "#         #Share Star - In Packet - GOOD\n",
    "# test_9 = np.array([-7,-6,-2,2])\n",
    "# test_10 = np.array([-7,-5,-2,2])\n",
    "# # print(in_packet(test_9,test_10))\n",
    "#         #Don't share star - In Packet GOOD\n",
    "# test_11 = test_9\n",
    "# test_12 = np.array([-7,-6,-1,1])\n",
    "# # print(in_packet(test_11,test_12))\n",
    "# # = k - 1 test cases GOOD\n",
    "#     #Both Type 2 - Should throw an error GOOD\n",
    "# test_13 = test_6\n",
    "# # print(in_packet(test_13,test_6))\n",
    "#     #Type 1 with Type 2 - Always in Packet GOOD\n",
    "# test_14 = np.array([-7,-6,-5,-3])\n",
    "# test_15 = np.array([-7,-6,-3,3])\n",
    "# # print(in_packet(test_14,test_15))\n",
    "#     #Type 1 with Type 1- Complicated\n",
    "#         #If intersection equals k - 1 - True GOOD\n",
    "# test_16 = np.array([-7,-6,-5,2])\n",
    "# test_17 = np.array([-7,-6,-5,3])\n",
    "# # print(in_packet(test_16,test_17))\n",
    "#         #If intersection is not k - 1 - False GOOD\n",
    "# test_18 = test_17\n",
    "# test_19 = np.array([-7,-6,5,2])\n",
    "# # print(in_packet(test_18,test_19))\n",
    "# # = k test cases GOOD\n",
    "#     #Type 1 with Type 1 - True GOOD\n",
    "# test_20 = np.array([-7,-6,-5,-4])\n",
    "# test_21 = np.array([-7,6,5,4])\n",
    "# # print(in_packet(test_20,test_21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Let's find some equivalences GOOD\n",
    "# J = [-3,-2,-1,1,2,3]\n",
    "# expression = all_sets(J,2)\n",
    "# flip(expression,[0,2])\n",
    "# find_all_packets(expression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word is usutsutst. Here are the equivalences: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dhoth\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:75: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([2, 3, array([-2, -1]), array([-3,  3])], dtype=object),\n",
       " array([5, 6, array([-3,  1]), array([-2,  2])], dtype=object)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('The word is {}. Here are the equivalences: '.format(w))\n",
    "find_equiv(long_words[w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word is usutsutst. Here are the packets: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({(-3, -2, -1): [array([-3, -2]), array([-3, -1]), array([-2, -1])]},\n",
       " {(-3, -2, -1): [0, 2]})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('The word is {}. Here are the packets: '.format(w))\n",
    "find_packets(long_words[w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new word is tsutstusu. It is True in the dictionary already.\n"
     ]
    }
   ],
   "source": [
    "w_new = 'tsutstusu'\n",
    "print('The new word is {}. It is {} in the dictionary already.'.format(w_new,w_new in long_words.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def old_in_packet(x,y):\n",
    "    packet = []\n",
    "    x = preferred_rep(x)\n",
    "    y = preferred_rep(y)\n",
    "    if np.all(x == y):\n",
    "        raise ValueError('Inputs are the same')\n",
    "    k = len(x)\n",
    "    abs_x, abs_y = abs(x),abs(y)\n",
    "    abs_int = np.intersect1d(abs_x,abs_y)\n",
    "    is_x_one = is_type_one(x)\n",
    "    is_y_one = is_type_one(y)\n",
    "    if len(abs_int) <= k - 3: #good\n",
    "        return []\n",
    "    elif len(abs_int) == k - 2: #Good\n",
    "        if is_x_one or is_y_one:\n",
    "            return []\n",
    "        else:\n",
    "            packet = np.sort(list(set(np.append(abs_x,abs_y))))\n",
    "            packet = np.append(packet, -packet[0])\n",
    "            packet = np.sort(-packet)\n",
    "            #return packet  \n",
    "    elif len(abs_int) == k - 1: \n",
    "        if is_x_one == True and is_y_one == True:\n",
    "            x_y_int = np.intersect1d(x,y)\n",
    "            if len(x_y_int) == k - 1:\n",
    "                missing = np.setdiff1d(y,x)\n",
    "                packet = np.sort(np.append(x,missing))\n",
    "                #return preferred_rep(packet)\n",
    "            elif len(x_y_int) ==  0:#Should this be k-2 or 0?\n",
    "                x_min = x[0]\n",
    "                y_min = y[0]\n",
    "                if y_min < x_min:\n",
    "                    c = np.copy(y)\n",
    "                    y = np.copy(x)\n",
    "                    x = c\n",
    "                x_last = x[1:]\n",
    "                if (len(np.setdiff1d(y,x_last)) == 1):\n",
    "                    packet = np.sort(np.union1d(x,y))\n",
    "                 #   return preferred_rep(packet)\n",
    "                elif (len(np.setdiff1d(-y,x_last)) == 1):\n",
    "                    packet = np.sort(np.union1d(x,-y))\n",
    "                  #  return preferred_rep(packet)\n",
    "                else:\n",
    "                    return []\n",
    "            else:\n",
    "                return []   \n",
    "        elif is_x_one == False and is_y_one == False:#x is Type 2 and y is Type 2, so they are the same\n",
    "            raise ValueError('Inputs are the same')\n",
    "        else:\n",
    "            if is_type_one(y):\n",
    "                y_hold = np.copy(y)\n",
    "                y = x\n",
    "                x = y_hold\n",
    "            packet = x\n",
    "            packet = np.append(packet, -packet[-1])\n",
    "            packet = np.sort(-packet)\n",
    "            #return preferred_rep(packet)\n",
    "    else: #if len(abs_int) == k: #only possible if both x and y are type 1 #Is this returning the right packet? Is this even right?\n",
    "        packet = np.sort(abs(x))\n",
    "        packet = np.append(packet,-packet[0])\n",
    "        packet = np.sort(-packet)\n",
    "        #return preferred_rep(packet)\n",
    "    if len(packet) > 0:\n",
    "        return preferred_rep(packet)\n",
    "    return []\n",
    "\n",
    "def old_old_in_packet(x,y):\n",
    "    x = preferred_rep(x)\n",
    "    y = preferred_rep(y)\n",
    "    if np.all(x == y):\n",
    "        raise ValueError('Inputs are the same')\n",
    "    k = len(x)\n",
    "    abs_x, abs_y = abs(x),abs(y)\n",
    "    abs_int = np.intersect1d(abs_x,abs_y)\n",
    "    is_x_one = is_type_one(x)\n",
    "    is_y_one = is_type_one(y)\n",
    "    if len(abs_int) <= k - 3: #good\n",
    "        return []\n",
    "    if len(abs_int) == k - 2: #Good\n",
    "        if is_x_one or is_y_one:\n",
    "            return []\n",
    "        else:\n",
    "            packet = np.sort(list(set(np.append(abs_x,abs_y))))\n",
    "            packet = np.append(packet, -packet[0])\n",
    "            packet = np.sort(-packet)\n",
    "            return packet  \n",
    "    if len(abs_int) == k - 1: \n",
    "        if is_x_one == True and is_y_one == True:\n",
    "            x_y_int = np.intersect1d(x,y)\n",
    "            if len(x_y_int) == k - 1:\n",
    "                missing = np.setdiff1d(y,x)\n",
    "                packet = np.sort(np.append(x,missing))\n",
    "                return preferred_rep(packet)\n",
    "            if len(x_y_int) ==  k-2:\n",
    "                x_min = x[0]\n",
    "                y_min = y[0]\n",
    "                if y_min < x_min:\n",
    "                    c = np.copy(y)\n",
    "                    y = np.copy(x)\n",
    "                    x = c\n",
    "                y_min = y[0]\n",
    "                x_second_min = x[1]\n",
    "                x_max = x[-1]\n",
    "                if (y_min < x_second_min) and (x_max == -y_min):\n",
    "                    missing = -np.setdiff1d(y,x)\n",
    "                    missing = np.setdiff1d(missing,y_min)\n",
    "                    packet = np.union1d(x,missing)\n",
    "                    return preferred_rep(packet)\n",
    "                else:\n",
    "                    return []\n",
    "            else:\n",
    "                 return []   \n",
    "        elif is_x_one == False and is_y_one == False:#x is Type 2 and y is Type 2, so they are the same\n",
    "            raise ValueError('Inputs are the same')\n",
    "        else:\n",
    "            if is_type_one(y):\n",
    "                y_hold = np.copy(y)\n",
    "                y = x\n",
    "                x = y_hold\n",
    "            packet = x\n",
    "            packet = np.append(packet, -packet[-1])\n",
    "            packet = np.sort(-packet)\n",
    "            return preferred_rep(packet)\n",
    "    if len(abs_int) == k: #only possible if both x and y are type 1 #Is this returning the right packet? Is this even right?\n",
    "        packet = np.sort(abs(x))\n",
    "        packet = np.append(packet,-packet[0])\n",
    "        packet = np.sort(-packet)\n",
    "        return preferred_rep(packet)\n",
    "    \n",
    "def old_adj_words(word,flips = True):\n",
    "    e_m = []\n",
    "    f_m = []\n",
    "    p_m = []\n",
    "    for e in find_equiv(word):\n",
    "        e_m.append(flip(word,[e[0],e[1]]))\n",
    "    if flips == True:\n",
    "        f1,f2 = find_packets(word)\n",
    "        for f in f2:\n",
    "            f_m.append(flip(word,f2[f]))\n",
    "            p_m.append(f)\n",
    "    e_m.reverse()\n",
    "    f_m.reverse()\n",
    "    p_m.reverse()\n",
    "    return e_m,f_m,p_m\n",
    "def old_find_packets(expression):\n",
    "    k = len(expression[0])\n",
    "    in_order_packets = {}\n",
    "    in_order_indices = {}\n",
    "    packet = []\n",
    "    for i in range(0,len(expression)-1):\n",
    "        #print('The characters are {} and {}'.format(expression[i],expression[i+1]))\n",
    "        poss_pack = in_packet(expression[i],expression[i+1])\n",
    "        if len(poss_pack) == 0:\n",
    "            #print(\"{} and {} are not in a packet together\".format(expression[i],expression[i+1]))\n",
    "            continue\n",
    "        elif is_type_one(poss_pack):\n",
    "            #print('{} and {} are in a type one packet together. \\n That packet is {}'.format(expression[i],expression[i+1],poss_pack))\n",
    "            packet = type_one_sets(poss_pack,k)\n",
    "        else:\n",
    "            #print('{} and {} are in a type two packet together. \\n That packet is {}'.format(expression[i],expression[i+1],poss_pack))\n",
    "            J = np.union1d(poss_pack,-poss_pack)\n",
    "            packet = all_sets(J,k)\n",
    "        if (i + len(packet)) <= len(expression):\n",
    "            subexp = expression[i:i+len(packet)] \n",
    "           # print('You are checking the packet {} in the subexpression {}'.format(poss_pack,subexp))\n",
    "            if pack_in_order(packet,subexp):\n",
    "                in_order_packets[tuple(poss_pack)] = packet\n",
    "                in_order_indices[tuple(poss_pack)] = [i, i+len(packet)-1]\n",
    "    return in_order_packets,in_order_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([-4,-3,2])\n",
    "y = np.array([-3,-2,-1])\n",
    "x_last = x[1:]\n",
    "len(np.setdiff1d(-y,x_last))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "while i < 10:\n",
    "    if i == 5:\n",
    "        i+=1\n",
    "        continue\n",
    "    print(i)\n",
    "    i+= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([0, 'a'])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = {0: 1, 'a':2}\n",
    "a.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
